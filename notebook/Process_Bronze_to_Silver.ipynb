{"cells":[{"cell_type":"markdown","source":["# Silver Layer Processing for Stock Quotes\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9a0ccd22-729f-4db9-9a4f-38879a78141a"},{"cell_type":"code","source":["# In this notebook, we’re taking raw JSON files from the Bronze layer and giving them structure.\n","# First, we apply a schema to make the data usable, then extract the stock symbol from the folder path.\n","# After cleaning things up, we save the result as a structured Delta table in the Silver layer.\n","# Let’s kick things off by loading the raw bronze data so we can start tidying it up.\n","\n","from pyspark.sql.functions import col, from_unixtime, input_file_name, regexp_extract\n","from pyspark.sql.types import DecimalType, TimestampType\n","\n","# We’re pointing to the raw Bronze data here.\n","# The '*' wildcard lets Spark scoop up files from all subfolders—handy when the data’s scattered.\n","\n","bronze_path = \"Files/bronze/trades/stock_symbol=*/*/*/*/*.json\"\n","\n","print(f\"Reading raw JSON data from: {bronze_path}\")\n","\n","try:\n","# Step 1: Let’s load the raw JSON files from the Bronze layer into a Spark DataFrame.\n","# This gives us a starting point to clean and shape the data before moving it up the pipeline.\n","    df_bronze = spark.read.option(\"multiLine\", \"true\").json(bronze_path)\n","\n","# Step 2: We’re pulling the stock symbol straight from the folder path and adding it as a new column.\n","# It’s a neat trick—super common in data engineering—and helps us tag each record with its source.\n","    df_with_symbol = df_bronze.withColumn(\"stock_symbol\", regexp_extract(input_file_name(), \"stock_symbol=([^/]+)\", 1))\n","\n","# Step 3: Time to shape the data—let’s pick the columns we need, rename them for clarity,\n","# and make sure each one has the right data type. This sets us up for smooth sailing downstream.\n","    df_silver = df_with_symbol.select(\n","        col(\"stock_symbol\"),\n","        col(\"c\").alias(\"price_current\").cast(DecimalType(10, 2)),\n","        col(\"d\").alias(\"price_change\").cast(DecimalType(10, 2)),\n","        col(\"dp\").alias(\"price_percent_change\").cast(DecimalType(10, 4)),\n","        col(\"h\").alias(\"price_high_day\").cast(DecimalType(10, 2)),\n","        col(\"l\").alias(\"price_low_day\").cast(DecimalType(10, 2)),\n","        col(\"o\").alias(\"price_open_day\").cast(DecimalType(10, 2)),\n","        col(\"pc\").alias(\"price_previous_close\").cast(DecimalType(10, 2)),\n","# Step 4: Let’s convert the Unix epoch timestamp into a readable datetime format.\n","# This makes it easier to work with time-based data—like filtering by date or plotting trends.\n","        from_unixtime(col(\"t\")).cast(TimestampType()).alias(\"timestamp_utc\")\n","    )\n","    \n","    print(\"Transformations complete. Showing a preview of the clean data:\")\n","    df_silver.show(5, truncate=False)\n","\n","# Step 5: Let’s write our cleaned DataFrame to the Silver Delta table.\n","# We’re using 'append' mode so each run adds fresh data without overwriting what’s already there.\n","# Partitioning by symbol helps speed up queries later—especially when we’re slicing by stock.\n","\n","    table_name = \"silver_stock_trades\"\n","    df_silver.write.format(\"delta\").mode(\"append\").partitionBy(\"stock_symbol\").saveAsTable(table_name)\n","    \n","    print(f\"SUCCESS: Cleaned data has been appended to the Silver table: '{table_name}'\")\n","\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"83f698a3-2799-4b99-b4a6-6a5d28fe9384","normalized_state":"finished","queued_time":"2025-08-22T16:11:20.7590635Z","session_start_time":"2025-08-22T16:11:20.7601461Z","execution_start_time":"2025-08-22T16:11:33.1046916Z","execution_finish_time":"2025-08-22T16:11:59.1370634Z","parent_msg_id":"b5cc0eac-383d-4ccc-8027-54f4e147e6f4"},"text/plain":"StatementMeta(, 83f698a3-2799-4b99-b4a6-6a5d28fe9384, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reading raw JSON data from: Files/bronze/trades/stock_symbol=*/*/*/*/*.json\nTransformations complete. Showing a preview of the clean data:\n+------------+-------------+------------+--------------------+--------------+-------------+--------------+--------------------+-------------------+\n|stock_symbol|price_current|price_change|price_percent_change|price_high_day|price_low_day|price_open_day|price_previous_close|timestamp_utc      |\n+------------+-------------+------------+--------------------+--------------+-------------+--------------+--------------------+-------------------+\n|AAPL        |230.56       |-0.33       |-0.1429             |232.87        |229.35       |231.28        |230.89              |2025-08-19 20:00:00|\n|AAPL        |227.36       |2.46        |1.0937              |228.72        |225.35       |225.35        |224.90              |2025-08-22 16:09:54|\n+------------+-------------+------------+--------------------+--------------+-------------+--------------+--------------------+-------------------+\n\nSUCCESS: Cleaned data has been appended to the Silver table: 'silver_stock_trades'\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5d9a47ba-66eb-4ef0-b104-fe04efbb1329"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"f6736f0a-7e3b-48e6-ba9c-dc982f312504","known_lakehouses":[{"id":"f6736f0a-7e3b-48e6-ba9c-dc982f312504"}],"default_lakehouse_name":"StockDataLakehouse","default_lakehouse_workspace_id":"18395274-3d83-48fb-8a37-3ccc2e3cab88"}}},"nbformat":4,"nbformat_minor":5}
