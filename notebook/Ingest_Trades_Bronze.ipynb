{"cells":[{"cell_type":"markdown","source":["# Bronze Layer Ingestion for Stock Quotes"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a330a660-b9cd-4141-be8f-ad87e77e7199"},{"cell_type":"code","source":["# This notebook grabs the latest stock quote data from the Finnhub API\n","# and drops it into the Bronze layer of our Lakehouse in raw JSON format.\n","# We’re using Hive-style partitioning here—it helps keep things organized and speeds up downstream processing.\n","\n","import requests\n","import json\n","from datetime import datetime\n","from notebookutils import mssparkutils\n","\n","# --- Configuration ---\n","# Just a heads-up: in production, we should manage secrets like API keys securely—\n","# something like Azure Key Vault works great for that.\n","\n","FINNHUB_API_KEY = 'd2gdc2hr01qq1lhui8e0d2gdc2hr01qq1lhui8eg' \n","STOCK_SYMBOL = 'AAPL'\n","BASE_URL = 'https://finnhub.io/api/v1/quote'\n","\n","try:\n","# Step 1: Let’s fetch the latest stock quote data from the Finnhub API.\n","# This gives us up-to-date market info to kick off our data pipeline.\n","    url = f\"{BASE_URL}?symbol={STOCK_SYMBOL}&token={FINNHUB_API_KEY}\"\n","    response = requests.get(url)\n","    response.raise_for_status()  # Ensures we stop on HTTP errors (4xx or 5xx).\n","    \n","    stock_data = response.json()\n","    print(f\"Successfully fetched data for {STOCK_SYMBOL}: {stock_data}\")\n","\n","# Step 2: Let’s define the path to our Bronze layer using Hive-style partitioning.\n","# This setup helps organize the data by key attributes—making it easier and faster to process later on.\n","    now = datetime.now()\n","    relative_directory_path = f\"Files/bronze/trades/stock_symbol={STOCK_SYMBOL}/year={now.strftime('%Y')}/month={now.strftime('%m')}/day={now.strftime('%d')}\"\n","    file_name = f\"{now.strftime('%Y%m%d_%H%M%S')}.json\"\n","    full_relative_path = f\"{relative_directory_path}/{file_name}\"\n","    \n","    print(f\"Target path: {full_relative_path}\")\n","\n","# Step 3: Now let’s save the raw JSON payload into the Bronze layer.\n","# This gives us a reliable snapshot of the incoming data—exactly as it arrived from the source.\n","    json_data_string = json.dumps(stock_data, indent=4)\n","    \n","# Before we write the file, let’s make sure the target directory actually exists.\n","# It’s a simple check that saves us from annoying write errors down the line.\n","    mssparkutils.fs.mkdirs(relative_directory_path)\n","    mssparkutils.fs.put(full_relative_path, json_data_string, True)\n","    \n","    print(f\"SUCCESS: Raw JSON for {STOCK_SYMBOL} landed in Bronze layer.\")\n","\n","except requests.exceptions.RequestException as e:\n","    print(f\"API Call Failed: {e}\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"87562db5-4053-422b-9d88-5df80c7888c4","normalized_state":"finished","queued_time":"2025-08-22T16:10:20.6435998Z","session_start_time":"2025-08-22T16:10:20.6446386Z","execution_start_time":"2025-08-22T16:10:33.5809655Z","execution_finish_time":"2025-08-22T16:10:38.1977106Z","parent_msg_id":"a55051c7-1b34-473e-80ed-1d527df4bac6"},"text/plain":"StatementMeta(, 87562db5-4053-422b-9d88-5df80c7888c4, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Successfully fetched data for AAPL: {'c': 227.3597, 'd': 2.4597, 'dp': 1.0937, 'h': 228.72, 'l': 225.35, 'o': 225.35, 'pc': 224.9, 't': 1755878994}\nTarget path: Files/bronze/trades/stock_symbol=AAPL/year=2025/month=08/day=22/20250822_161034.json\nSUCCESS: Raw JSON for AAPL landed in Bronze layer.\n"]}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c5397b2b-d01d-4439-a3c9-5a34ab0ea7e7"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"f6736f0a-7e3b-48e6-ba9c-dc982f312504","known_lakehouses":[{"id":"f6736f0a-7e3b-48e6-ba9c-dc982f312504"}],"default_lakehouse_name":"StockDataLakehouse","default_lakehouse_workspace_id":"18395274-3d83-48fb-8a37-3ccc2e3cab88"}}},"nbformat":4,"nbformat_minor":5}
